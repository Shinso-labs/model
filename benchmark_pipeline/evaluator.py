"""Evaluation metrics for comparing generated Move code with reference implementations."""

import difflib
import re
import subprocess
import tempfile
import os
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from collections import Counter
import math
from logger_config import get_logger

# Initialize logger for this module
logger = get_logger('evaluator')


@dataclass
class EvaluationResult:
    """Results from evaluating a translation."""
    test_case: str
    syntax_score: float  # 0-100, basic syntax checks
    similarity_score: float  # 0-100, text similarity
    structure_score: float  # 0-100, structural similarity
    bleu_score: float  # 0-100, BLEU score for code similarity
    semantic_score: float  # 0-100, semantic equivalence
    compilable: Optional[bool]  # Whether the code compiles
    line_diff: List[str]  # Diff output
    metrics: Dict[str, Any]  # Additional metrics
    passed: bool  # Overall pass/fail


class MoveCodeEvaluator:
    """Evaluates generated Move code against reference implementations."""

    def __init__(self):
        # Common Move keywords and patterns
        self.move_keywords = {
            'module', 'struct', 'fun', 'entry', 'public', 'has', 'key', 'store',
            'use', 'let', 'mut', 'return', 'if', 'else', 'while', 'loop',
            'break', 'continue', 'abort', 'transfer', 'object', 'tx_context'
        }

    def evaluate(self, generated_code: str, reference_code: str, test_case: str) -> EvaluationResult:
        """
        Evaluate generated Move code against reference implementation.

        Args:
            generated_code: The code generated by the model
            reference_code: The reference/expected code
            test_case: Name of the test case

        Returns:
            EvaluationResult with various metrics
        """
        logger.debug(f"[{test_case}] Starting evaluation - generated: {len(generated_code)} chars, reference: {len(reference_code)} chars")

        # Calculate different similarity metrics
        logger.debug(f"[{test_case}] Checking syntax...")
        syntax_score = self._check_syntax(generated_code)

        logger.debug(f"[{test_case}] Calculating text similarity...")
        similarity_score = self._calculate_text_similarity(generated_code, reference_code)

        logger.debug(f"[{test_case}] Calculating structure similarity...")
        structure_score = self._calculate_structure_similarity(generated_code, reference_code)

        logger.debug(f"[{test_case}] Calculating BLEU score...")
        bleu_score = self._calculate_bleu_score(generated_code, reference_code)

        logger.debug(f"[{test_case}] Calculating semantic similarity...")
        semantic_score = self._calculate_semantic_similarity(generated_code, reference_code)

        logger.debug(f"[{test_case}] Generating diff...")
        line_diff = self._generate_diff(generated_code, reference_code)

        # Check if code compiles (optional - requires sui CLI)
        logger.debug(f"[{test_case}] Checking compilation...")
        compilable = self._check_compilation(generated_code)

        # Extract additional metrics
        logger.debug(f"[{test_case}] Extracting code structure metrics...")
        gen_funcs = self._extract_functions(generated_code)
        ref_funcs = self._extract_functions(reference_code)
        gen_structs = self._extract_structs(generated_code)
        ref_structs = self._extract_structs(reference_code)

        metrics = {
            "generated_lines": len(generated_code.splitlines()) if generated_code else 0,
            "reference_lines": len(reference_code.splitlines()) if reference_code else 0,
            "has_module_declaration": self._has_module_declaration(generated_code),
            "struct_count_generated": len(gen_structs),
            "struct_count_reference": len(ref_structs),
            "function_count_generated": len(gen_funcs),
            "function_count_reference": len(ref_funcs),
            "struct_match_ratio": self._calculate_match_ratio(gen_structs, ref_structs),
            "function_match_ratio": self._calculate_match_ratio(gen_funcs, ref_funcs),
            "keyword_coverage": self._calculate_keyword_coverage(generated_code, reference_code),
            "exact_match": generated_code.strip() == reference_code.strip(),
            "generated_empty": len(generated_code.strip()) == 0,
        }

        logger.debug(f"[{test_case}] Extracted metrics: {gen_funcs} funcs, {gen_structs} structs")

        # Determine overall pass/fail with enhanced criteria
        passed = (
            syntax_score >= 50 and
            semantic_score >= 40 and
            structure_score >= 40 and
            bleu_score >= 20 and
            not metrics["generated_empty"]
        )

        logger.debug(f"[{test_case}] Evaluation complete - passed: {passed}")
        logger.debug(f"[{test_case}] Scores - syntax:{syntax_score:.1f}, semantic:{semantic_score:.1f}, structure:{structure_score:.1f}, bleu:{bleu_score:.1f}")

        return EvaluationResult(
            test_case=test_case,
            syntax_score=syntax_score,
            similarity_score=similarity_score,
            structure_score=structure_score,
            bleu_score=bleu_score,
            semantic_score=semantic_score,
            compilable=compilable,
            line_diff=line_diff,
            metrics=metrics,
            passed=passed
        )

    def _check_syntax(self, code: str) -> float:
        """Basic syntax checking for Move code."""
        score = 0.0
        checks = 0

        # Check 1: Has module declaration
        checks += 1
        if re.search(r'module\s+\w+::\w+', code):
            score += 20

        # Check 2: Proper use statements
        checks += 1
        if 'use' in code and '::' in code:
            score += 15

        # Check 3: Has struct or function definitions
        checks += 1
        if re.search(r'(struct\s+\w+|fun\s+\w+)', code):
            score += 20

        # Check 4: Proper braces matching
        checks += 1
        if code.count('{') == code.count('}'):
            score += 20

        # Check 5: Has Move-specific patterns
        checks += 1
        move_patterns = ['TxContext', 'UID', 'object::', 'transfer::', 'tx_context::']
        if any(pattern in code for pattern in move_patterns):
            score += 25

        return score

    def _calculate_text_similarity(self, generated: str, reference: str) -> float:
        """Calculate text similarity using sequence matcher."""
        matcher = difflib.SequenceMatcher(None, generated, reference)
        return matcher.ratio() * 100

    def _calculate_structure_similarity(self, generated: str, reference: str) -> float:
        """Calculate structural similarity by comparing code elements."""
        gen_elements = self._extract_code_elements(generated)
        ref_elements = self._extract_code_elements(reference)

        if not ref_elements:
            return 0.0

        # Calculate overlap
        common = sum(1 for elem in ref_elements if elem in gen_elements)
        return (common / len(ref_elements)) * 100

    def _extract_code_elements(self, code: str) -> List[str]:
        """Extract key code elements (module, structs, functions)."""
        elements = []

        # Extract module name
        module_match = re.search(r'module\s+(\w+::\w+)', code)
        if module_match:
            elements.append(f"module:{module_match.group(1)}")

        # Extract struct names
        struct_matches = re.finditer(r'struct\s+(\w+)', code)
        for match in struct_matches:
            elements.append(f"struct:{match.group(1)}")

        # Extract function names
        fun_matches = re.finditer(r'fun\s+(\w+)', code)
        for match in fun_matches:
            elements.append(f"fun:{match.group(1)}")

        return elements

    def _generate_diff(self, generated: str, reference: str) -> List[str]:
        """Generate unified diff between generated and reference code."""
        gen_lines = generated.splitlines(keepends=True)
        ref_lines = reference.splitlines(keepends=True)

        diff = list(difflib.unified_diff(
            ref_lines,
            gen_lines,
            fromfile='reference.move',
            tofile='generated.move',
            lineterm=''
        ))

        return diff

    def _has_module_declaration(self, code: str) -> bool:
        """Check if code has a proper module declaration."""
        return bool(re.search(r'module\s+\w+::\w+', code))

    def _count_structs(self, code: str) -> int:
        """Count struct definitions."""
        return len(re.findall(r'struct\s+\w+', code))

    def _count_functions(self, code: str) -> int:
        """Count function definitions."""
        return len(re.findall(r'fun\s+\w+', code))

    def _calculate_keyword_coverage(self, generated: str, reference: str) -> float:
        """Calculate what percentage of Move keywords from reference appear in generated."""
        ref_keywords = {word for word in reference.split() if word in self.move_keywords}
        gen_keywords = {word for word in generated.split() if word in self.move_keywords}

        if not ref_keywords:
            return 100.0

        common = ref_keywords & gen_keywords
        return (len(common) / len(ref_keywords)) * 100

    def _calculate_bleu_score(self, generated: str, reference: str, n: int = 4) -> float:
        """
        Calculate BLEU score for code similarity.

        Args:
            generated: Generated code
            reference: Reference code
            n: Maximum n-gram size (default 4)

        Returns:
            BLEU score scaled to 0-100
        """
        if not generated or not reference:
            return 0.0

        # Tokenize code (split by whitespace and special characters)
        gen_tokens = self._tokenize_code(generated)
        ref_tokens = self._tokenize_code(reference)

        if not gen_tokens or not ref_tokens:
            return 0.0

        # Calculate n-gram precisions
        precisions = []
        for i in range(1, n + 1):
            gen_ngrams = self._get_ngrams(gen_tokens, i)
            ref_ngrams = self._get_ngrams(ref_tokens, i)

            if not gen_ngrams:
                precisions.append(0.0)
                continue

            # Count matches
            matches = sum((gen_ngrams & ref_ngrams).values())
            total = sum(gen_ngrams.values())
            precision = matches / total if total > 0 else 0.0
            precisions.append(precision)

        # Calculate geometric mean of precisions
        if not precisions or all(p == 0 for p in precisions):
            return 0.0

        # Apply smoothing for zero precisions
        smoothed_precisions = [max(p, 1e-10) for p in precisions]
        geo_mean = math.exp(sum(math.log(p) for p in smoothed_precisions) / len(smoothed_precisions))

        # Brevity penalty
        bp = min(1.0, math.exp(1 - len(ref_tokens) / max(len(gen_tokens), 1)))

        bleu = bp * geo_mean
        return bleu * 100  # Scale to 0-100

    def _tokenize_code(self, code: str) -> List[str]:
        """Tokenize code for BLEU calculation."""
        # Split on whitespace and common separators
        tokens = re.findall(r'\w+|[^\w\s]', code.lower())
        return [t for t in tokens if t.strip()]

    def _get_ngrams(self, tokens: List[str], n: int) -> Counter:
        """Get n-grams from token list."""
        ngrams = Counter()
        for i in range(len(tokens) - n + 1):
            ngram = tuple(tokens[i:i+n])
            ngrams[ngram] += 1
        return ngrams

    def _calculate_semantic_similarity(self, generated: str, reference: str) -> float:
        """
        Calculate semantic similarity based on structural elements.

        Compares:
        - Module declarations
        - Struct definitions and their fields
        - Function signatures
        - Import statements
        """
        if not generated or not reference:
            return 0.0

        score = 0.0
        total_checks = 0

        # Check module declaration
        total_checks += 1
        gen_module = self._extract_module_name(generated)
        ref_module = self._extract_module_name(reference)
        if gen_module and ref_module:
            # Module names might differ, check structure exists
            score += 20

        # Check struct definitions
        total_checks += 1
        gen_structs = self._extract_structs(generated)
        ref_structs = self._extract_structs(reference)
        struct_similarity = self._calculate_match_ratio(gen_structs, ref_structs)
        score += struct_similarity * 30  # 30% weight

        # Check function definitions
        total_checks += 1
        gen_functions = self._extract_functions(generated)
        ref_functions = self._extract_functions(reference)
        func_similarity = self._calculate_match_ratio(gen_functions, ref_functions)
        score += func_similarity * 30  # 30% weight

        # Check imports
        total_checks += 1
        gen_imports = self._extract_imports(generated)
        ref_imports = self._extract_imports(reference)
        import_similarity = self._calculate_match_ratio(gen_imports, ref_imports)
        score += import_similarity * 20  # 20% weight

        return min(score, 100.0)

    def _extract_module_name(self, code: str) -> Optional[str]:
        """Extract module name from code."""
        match = re.search(r'module\s+(\w+::\w+)', code)
        return match.group(1) if match else None

    def _extract_structs(self, code: str) -> List[str]:
        """Extract struct definitions with their fields."""
        structs = []
        # Match struct definitions including their bodies
        pattern = r'struct\s+(\w+)\s*(?:<[^>]+>)?\s*(?:has\s+[^{]+)?\s*\{'
        for match in re.finditer(pattern, code):
            structs.append(match.group(1))
        return structs

    def _extract_functions(self, code: str) -> List[str]:
        """Extract function signatures."""
        functions = []
        # Match function definitions
        pattern = r'(?:public\s+)?(?:entry\s+)?fun\s+(\w+)'
        for match in re.finditer(pattern, code):
            functions.append(match.group(1))
        return functions

    def _extract_imports(self, code: str) -> List[str]:
        """Extract import statements."""
        imports = []
        pattern = r'use\s+([\w:]+)'
        for match in re.finditer(pattern, code):
            imports.append(match.group(1))
        return imports

    def _calculate_match_ratio(self, generated_items: List[str], reference_items: List[str]) -> float:
        """Calculate match ratio between two lists of items."""
        if not reference_items:
            return 100.0 if not generated_items else 0.0

        if not generated_items:
            return 0.0

        # Convert to sets for comparison
        gen_set = set(generated_items)
        ref_set = set(reference_items)

        # Calculate Jaccard similarity
        intersection = len(gen_set & ref_set)
        union = len(gen_set | ref_set)

        return (intersection / union * 100) if union > 0 else 0.0

    def _check_compilation(self, code: str) -> Optional[bool]:
        """
        Check if generated Move code compiles.

        Returns:
            True if compiles, False if doesn't, None if sui CLI not available
        """
        if not code or not code.strip():
            logger.debug("Empty code provided for compilation check")
            return False

        try:
            # Check if sui CLI is available
            logger.debug("Checking for sui CLI availability...")
            result = subprocess.run(['sui', '--version'],
                                  capture_output=True,
                                  timeout=5)
            if result.returncode != 0:
                logger.debug("sui CLI not available (non-zero return code)")
                return None  # sui CLI not available
        except (subprocess.TimeoutExpired, FileNotFoundError) as e:
            logger.debug(f"sui CLI not available: {e}")
            return None  # sui CLI not available

        # Create a temporary directory with proper Move package structure
        with tempfile.TemporaryDirectory() as tmpdir:
            logger.debug(f"Created temporary directory for compilation: {tmpdir}")

            # Create Move.toml
            move_toml = """[package]
name = "test_package"
version = "0.0.1"

[dependencies]
Sui = { git = "https://github.com/MystenLabs/sui.git", subdir = "crates/sui-framework/packages/sui-framework", rev = "framework/mainnet" }

[addresses]
test_package = "0x0"
"""
            with open(os.path.join(tmpdir, 'Move.toml'), 'w') as f:
                f.write(move_toml)

            # Create sources directory
            sources_dir = os.path.join(tmpdir, 'sources')
            os.makedirs(sources_dir)

            # Write the generated code
            code_file = os.path.join(sources_dir, 'generated.move')
            with open(code_file, 'w') as f:
                f.write(code)
            logger.debug(f"Wrote code to {code_file}")

            # Try to build
            try:
                logger.debug("Running 'sui move build'...")
                result = subprocess.run(
                    ['sui', 'move', 'build'],
                    cwd=tmpdir,
                    capture_output=True,
                    timeout=30
                )

                if result.returncode == 0:
                    logger.debug("Compilation successful!")
                    return True
                else:
                    logger.debug(f"Compilation failed with return code {result.returncode}")
                    logger.debug(f"Compilation stderr: {result.stderr.decode('utf-8')[:500]}")
                    return False
            except subprocess.TimeoutExpired:
                logger.warning("Compilation timed out after 30 seconds")
                return False
            except Exception as e:
                logger.error(f"Compilation error: {e}", exc_info=True)
                return False
